# References and helpful links 
References and helpful/useful links used in iust_deep_fuzz project
(to be updated incrementally).

Provide by: Morteza Zakeri

## Code

### Sequence learning 

[4] [Sequence Models](https://www.coursera.org/learn/nlp-sequence-models/lecture/fyXnn/bidirectional-rnn)

[3] [Bright Wire](http://www.jackdermody.net/brightwire/article/Sequence_to_Sequence_with_LSTM)

[2] [The unreasonable effectiveness of Character-level Language Models](http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139)

[1] [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by A. Karpathy


### Code coverage measurement
[2] [Pin - A Binary Instrumentation Tool - Downloads](https://software.intel.com/en-us/articles/pin-a-binary-instrumentation-tool-downloads)

[1] [Plugin for code coverage with pintool](https://github.com/gaasedelen/lighthouse/tree/master/coverage/pin)


### Perplexity measurement 
[6] [2012_Statistical Language Models Based on Neural Networks]()

[5] [Perplexity](http://www1.icsi.berkeley.edu/Speech/docs/HTKBook3.2/node188_mn.html)

[4] [What is perplexity?](https://stats.stackexchange.com/questions/10302/what-is-perplexity)

[3] [comparing-perplexities](https://stats.stackexchange.com/questions/242617/comparing-perplexities-with-different-data-set-sizes?noredirect=1&lq=1)

[2] [Computing perplexity as a metric: K.pow() doesn't work?!](https://github.com/keras-team/keras/issues/8267)

[1] [how-to-calculate-perplexity-of-rnn-in-tensorflow](https://stackoverflow.com/questions/41881308/how-to-calculate-perplexity-of-rnn-in-tensorflow)


## Papers
