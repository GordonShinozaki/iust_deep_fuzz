Index: incremental_update/pdf_file_incremental_update_6.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\"\"\"\r\nIncremental update pdf file\r\n- New in version 6\r\n-- Eliminate inject binary object when generate test data.\r\n- New in version 5\r\n-- Add for use in remote server with global config file.\r\n- New in version 4\r\n-- Add online support to generate object from model.\r\n- New in version 3\r\n-- Add binary stream to object which have stream keyword\r\n-- Fuzz binary streams with mutation-based algorithms.\r\n- New in version 2\r\n-- Attach multi-object to end of the pdf file. base on 'portion_of_rewrite_objects' in config.py\r\n\"\"\"\r\n\r\n__version__ = '0.6.0'\r\n__author__ = 'Morteza'\r\n\r\nimport sys\r\nimport os\r\n\r\nimport math\r\nimport random\r\nimport datetime\r\n\r\nimport PyPDF2\r\n\r\n# sys.path.insert(0, '..')\r\nfrom config import iu_config\r\nimport pdf_object_preprocess as preprocess\r\n# from lstm_text_generation_pdf_objs_8 import FileFormatFuzzer\r\n\r\n\r\nclass IncrementalUpdate(object):\r\n    \"\"\"\r\n    Implement simple way to update a pdf file.\r\n    \"\"\"\r\n    def __init__(self,\r\n                 host_id=None,\r\n                 object_file_path=iu_config['new_objects_path'],\r\n                 stream_directory_path=iu_config['stream_directory_path']):\r\n        \"\"\"\r\n\r\n        :param host_id: Name of host file without postfix, e.g. host1_max, host2_min or host3_avg\r\n        :param object_file_path: See iu_config, new_objects_path\r\n        :param stream_directory_path: See iu_config, stream_directory_path\r\n        \"\"\"\r\n        self.host_id = host_id\r\n\r\n        self.object_file_path = object_file_path\r\n        self.obj_list = self.__get_objects_sequence()\r\n\r\n        self.stream_directory_path = stream_directory_path\r\n        self.stream_filename_list = os.listdir(self.stream_directory_path)\r\n\r\n        # Creating new directory foreach time that program run and we want to generate new test data\r\n        dt = datetime.datetime.now().strftime(self.host_id + '_date_%Y-%m-%d_%H-%M-%S')\r\n        self.storage_dir_name = iu_config['new_pdfs_directory'] + self.host_id + '/' + dt + '/'\r\n        if not os.path.exists(self.storage_dir_name):\r\n            os.makedirs(self.storage_dir_name)\r\n            print('New storage directory build.')\r\n\r\n        self.obj_getter = self.obj_generator(self.obj_list)\r\n\r\n        # retval = os.getcwd()\r\n        # os.chdir('../')\r\n        # print(os.getcwd())\r\n        # self.fff = FileFormatFuzzer(maxlen=50, step=1, batch_size=256)\r\n        #\r\n        # self.object_buffer_list = self.fff.load_model_and_generate()\r\n        # self.object_buffer_index = 0\r\n        # os.chdir(retval)\r\n\r\n    def read_pdf_file(self):\r\n        with open(iu_config['raw_host_directory'] + self.host_id + '.pdf', 'rb') as f:\r\n            data = f.read()\r\n        return data\r\n\r\n    def write_pdf_file(self, name_description, data):\r\n        with open(self.storage_dir_name + self.host_id + name_description + '.pdf', 'wb') as f:\r\n            f.write(data)\r\n\r\n    def __get_objects_sequence(self):\r\n        seq = ''\r\n        for filename in os.listdir(self.object_file_path):\r\n            try:\r\n                seq += preprocess.load_from_file(self.object_file_path + filename)\r\n            except Exception as e:\r\n                print('Extracting failed from %s:' % filename, file=sys.stderr)\r\n                print(str(e), file=sys.stderr)\r\n            # finally:\r\n        obj_list = preprocess.get_list_of_object(seq=seq, is_sort=False)\r\n        print('obj_list len', len(obj_list))\r\n        print(obj_list)\r\n        # for o in obj_list:\r\n        #     print(o, '\\n', '#'*50)\r\n        # input()\r\n        return obj_list\r\n\r\n    def obj_generator(self, obj_list):\r\n        i = 0\r\n        while True:\r\n            yield obj_list[i]\r\n            i += 1\r\n            if i >= len(obj_list):\r\n                i = random.randint(0, len(obj_list)-2)\r\n\r\n    def get_one_object(self, getting_object_policy=iu_config['getting_object_policy'], from_model=False):\r\n        \"\"\"\r\n        Provide one pdf data object whether an existing object in corpus or\r\n        an online new generated object from learnt model\r\n        this function is not complete yet!\r\n        when complete it is expected to get object coming from deep model (learn_and_fuzz) algorithm\r\n        \"\"\"\r\n        obj = ''\r\n        if from_model:\r\n            obj = self.__get_one_object_from_model()\r\n        else:\r\n            if getting_object_policy == 'sequential':\r\n                # For now using object getter generator\r\n                obj = next(self.obj_getter)\r\n                print(obj)\r\n                # x = input()\r\n            elif getting_object_policy == 'random':\r\n                # For now randomly choose as object from given obj_list\r\n                random_object_index = random.randint(0, len(self.obj_list) - 1)\r\n                obj = self.obj_list[random_object_index]\r\n\r\n        # Recently added (1397-01-16)\r\n        # Check if selected object contain keyword 'stream' then add a random/ and fuzzed binary stream to\r\n        # selected object.\r\n        stream_index = obj.find('stream')\r\n        obj = bytes(obj, encoding='ascii')\r\n        # if stream_index != -1:\r\n        if False:\r\n            # random_stream_index = random.randint(0, len(self.stream_filename_list)-1)\r\n            # with open(self.stream_directory_path+self.stream_filename_list[random_stream_index], mode='rb') as f:\r\n            #     binary_stream = f.read()\r\n            # Fuzz binary stream separately.\r\n            # We use generation fuzzing for pdf data objects and mutation fuzzing for pdf binary streams that exist\r\n            # within our pdf data objects\r\n            # binary_stream = self.fuzz_binary_stream(binary_stream)\r\n            # obj = obj[:stream_index+7] + binary_stream + bytes('\\nendstream\\n', encoding='ascii') + obj[stream_index+7:]\r\n            # obj = obj[:stream_index + 7] + obj[stream_index + 7:]\r\n            obj = obj[:stream_index] + obj[stream_index + 7:]  # Fix above line.\r\n            print('binary_stream not add.')\r\n            # print(obj)\r\n\r\n        return obj\r\n\r\n    '''\r\n    def __get_one_object_from_model(self):\r\n        \"\"\"\r\n\r\n        :return:\r\n        \"\"\"\r\n        if self.object_buffer_index < len(self.object_buffer_list):\r\n            temp = self.object_buffer_index\r\n            self.object_buffer_index += 1\r\n            return self.object_buffer_list[temp]\r\n        else:\r\n            self.object_buffer_index = 0\r\n            retval = os.getcwd()\r\n            os.chdir('../')\r\n            self.object_buffer_list = self.fff.load_model_and_generate()\r\n            obj = self.__get_one_object_from_model()\r\n            os.chdir(retval)\r\n            return obj\r\n    '''\r\n\r\n    def get_last_object_id(self):\r\n        with open(iu_config['raw_host_directory'] + self.host_id + '.pdf', 'br') as f:\r\n            read_pdf = PyPDF2.PdfFileReader(f)\r\n        last_object_id = read_pdf.trailer['/Size'] - 1  # size xref  - 1\r\n        return last_object_id\r\n\r\n    def incremental_update(self, sequential_number=0):\r\n        \"\"\"\r\n        Shape the incremental update behaviour\r\n        :param sequential_number: Number appear at the end of new pdf file name as identity number (e.g. 1,2 and 3)\r\n        :return: Nothing\r\n        \"\"\"\r\n        data = self.read_pdf_file()\r\n        last_object_id = str(self.get_last_object_id())\r\n        rewrite_object_content = self.get_one_object()  # Updated. Now include stream objects.\r\n\r\n        if iu_config['single_object_update']:  # Just one object rewrite with new content\r\n            if iu_config['update_policy'] == 'random':\r\n                # Random choose between [2,:] because we don't want modify first object at any condition.\r\n                rewrite_object_id = str(random.randint(2, int(last_object_id)))\r\n            elif iu_config['update_policy'] == 'bottom_up':\r\n                rewrite_object_id = last_object_id\r\n            else:\r\n                rewrite_object_id = last_object_id\r\n            data = self.attach_new_object(data=data,\r\n                                          rewrite_object_id=rewrite_object_id,\r\n                                          rewrite_object_content=rewrite_object_content)\r\n            # Set name for new pdf files like:\r\n            # host1_sou_85_6_20180307_114117\r\n            # dt = datetime.datetime.now().strftime('_%Y%m%d_%H%M%S')\r\n            name_description = '_sou_' + str(sequential_number).zfill(4) + '_obj-' + str(rewrite_object_id).zfill(3)\r\n            self.write_pdf_file(name_description, data)\r\n            print('save new pdf file successfully')\r\n        else:  # Multiple object rewrite with new content (base on 'portion_of_rewrite_objects') in config file\r\n            poro = iu_config['portion_of_rewrite_objects']\r\n            # Special config for my thesis tests.\r\n            if self.host_id == 'host1_max':\r\n                poro = 1/5.\r\n            elif self.host_id == 'host2_min':\r\n                poro = 1/3.\r\n            elif self.host_id == 'host3_avg':\r\n                poro = 1/4.\r\n            number_of_rewrite_objects = math.ceil(poro * int(last_object_id))\r\n            # print(host_id, number_of_of_rewrite_objects)\r\n            rewrite_object_id = last_object_id\r\n            rewrite_object_ids = ''\r\n            for i in range(int(number_of_rewrite_objects)):\r\n                rewrite_object_content = self.get_one_object()\r\n                if iu_config['update_policy'] == 'random':\r\n                    # Random choose between [2,:] because we don't want modify first object at any condition.\r\n                    rewrite_object_id = str(random.randint(2, int(last_object_id)))\r\n                elif iu_config['update_policy'] == 'bottom_up':\r\n                    rewrite_object_id = int(last_object_id) - i\r\n                elif iu_config['update_policy'] == 'top-down':\r\n                    # Not implement yet.\r\n                    pass\r\n                rewrite_object_ids += '-' + str(rewrite_object_id).zfill(3)\r\n                data = self.attach_new_object(data=data,\r\n                                              rewrite_object_id=rewrite_object_id,\r\n                                              rewrite_object_content=rewrite_object_content)\r\n            # Set name for new pdf files like:\r\n            # host1_sou_85_6_20180307_114117\r\n            # dt = datetime.datetime.now().strftime('_%Y%m%d_%H%M%S')\r\n            if self.host_id == 'host1_max':\r\n                name_description = '_mou_' + str(sequential_number).zfill(4) + '_' + '20percent'\r\n            else:\r\n                name_description = '_mou_' + str(sequential_number).zfill(4) + '_' + str(rewrite_object_ids)\r\n            self.write_pdf_file(name_description, data)\r\n            print('save new pdf file successfully')\r\n\r\n    @staticmethod\r\n    def attach_new_object(data=None,\r\n                          rewrite_object_id=None,\r\n                          rewrite_object_content=None):\r\n        \"\"\"\r\n        Incremental update pdf file\r\n        :param data:\r\n        :param rewrite_object_id: pdf object id w want to update\r\n        :param rewrite_object_content: new content fo pdf object\r\n        :return:\r\n        \"\"\"\r\n\r\n        # Find last trailer in a pdf file\r\n        trailer_index = 0\r\n        while data.find(b'trailer', trailer_index + 7) != -1:\r\n            trailer_index = data.find(b'trailer', trailer_index + 7)\r\n        print('trailer_index', trailer_index)\r\n\r\n        trailer_index_dic_endof = data.find(b'>>', trailer_index)\r\n        print('trailer_index_dic_endof', trailer_index_dic_endof)\r\n\r\n        trailer_content = data[trailer_index: trailer_index_dic_endof + 2]\r\n        print('trailer_content', trailer_content)\r\n\r\n        # find last startxref offset in a pdf file\r\n        startxref_index = trailer_index\r\n        while data.find(b'startxref', startxref_index + 9) != -1:\r\n            startxref_index = data.find(b'startxref', startxref_index + 9)\r\n        # print('index ===', index_startxref)\r\n        index_eof = data.find(b'%%EOF', startxref_index)\r\n        # print('index 2===', index_eof)\r\n        if data[startxref_index + 9] == b'\\n' or b'\\r':\r\n            # print('yes', data[index_startxref+9])\r\n            startxref_index += 10\r\n        if data[index_eof - 1] == b'\\n' or b'\\r':\r\n            index_eof -= 1\r\n        startxref_offset = int(data[startxref_index: index_eof])\r\n        print('startxref_offset', startxref_offset)\r\n\r\n        # print(type(trailer_content))\r\n        # remove all /Prev 1234 from trailer if exist\r\n        # trailer_content = trailer_content.replace(b'/Prev', b'')\r\n        # trailer_content = re.sub(r'/Prev \\d+', b'', str(trailer_content))\r\n        index_prev = trailer_content.find(b'/Prev')\r\n        if index_prev != -1:\r\n            index_curr = 0\r\n            # print('##', trailer_content[index_prev+5], index_prev)\r\n            # check whether a byte is ascii number or space\r\n            eliminate_content = trailer_content[index_prev+5+index_curr]\r\n            # print('eliminate content', eliminate_content)\r\n            while (48 <= eliminate_content <= 57) or (eliminate_content == 32):\r\n                # print('###', trailer_content[index_prev+5+index_curr])\r\n                index_curr += 1\r\n                eliminate_content = trailer_content[index_prev + 5 + index_curr]\r\n\r\n            trailer_content = trailer_content[:index_prev] + trailer_content[index_prev+5+index_curr:]\r\n\r\n        trailer_content_new = trailer_content[:-2] + b'   /Prev ' \\\r\n                              + bytes(str(startxref_offset), 'ascii') + b' \\n>>'\r\n        # print('trailer_content_new', trailer_content_new)\r\n\r\n        # print('len_rewrite_object_content', len(rewrite_object_content))\r\n        startxref_offset_new = len(data) + 1 + len(rewrite_object_id) + 3 + len(rewrite_object_content)  # if we attach just one obj\r\n        # print('startxref_offset_new', startxref_offset_new)\r\n\r\n        attach_content = bytes(str(rewrite_object_id + ' 0 '), encoding='ascii')\\\r\n                         + rewrite_object_content\\\r\n                         + bytes('\\nxref\\n0 1\\n0000000000 65535 f\\n'\r\n                                 + rewrite_object_id\r\n                                 + ' 1\\n'\r\n                                 + str(len(data)).zfill(10)\r\n                                 + ' 00000 n\\n', encoding='ascii')\r\n        attach_content = attach_content \\\r\n                         + trailer_content_new \\\r\n                         + b'\\nstartxref\\n'\\\r\n                         + bytes(str(startxref_offset_new), encoding='ascii')\\\r\n                         + b'\\n%%EOF\\n'\r\n\r\n        # print('attach_content\\n', attach_content)\r\n        new_pdf_file = data + attach_content\r\n        return new_pdf_file\r\n\r\n    @staticmethod\r\n    def fuzz_binary_stream(binary_stream):\r\n        \"\"\"\r\n        Fuzzing fuzzing_policy for binary stream fuzz testing.\r\n        Simple basic fuzzing fuzzing_policy:\r\n        Reverse 1% of all bytes in stream randomly. Below code do this\r\n        :param binary_stream:\r\n        :return: fuzzed_binary_stream\r\n        \"\"\"\r\n        if iu_config['stream_fuzzing_policy'] == 'basic_random':\r\n            for i in range(math.ceil(len(binary_stream)/100)):\r\n                # Choose one byte randomly\r\n                byte_to_reverse_index = random.randint(0, len(binary_stream)-1)\r\n                one_byte = binary_stream[byte_to_reverse_index]\r\n\r\n                # Convert byte int representation to byte binary string representation (Step 2)\r\n                eight_bit = \"{0:b}\".format(one_byte)\r\n                # print('eight_bit of one_bye', eight_bit)\r\n\r\n                # Reverse eight_bit e.g. 0110000 ==> 1001111\r\n                eight_bit_reverse_str = ''\r\n                for j in range(len(eight_bit)):\r\n                    if eight_bit[j] == '1':\r\n                        eight_bit_reverse_str += '0'\r\n                    else:\r\n                        eight_bit_reverse_str += '1'\r\n                # print('eight_bit_reverse_str', eight_bit_reverse_str)\r\n\r\n                # Back eight_bit_reverse_str to int representation (Reverse of step 2)\r\n                eight_bit_reverse_int = int(eight_bit_reverse_str, 2)\r\n\r\n                # Convert eight_bit_reverse_int to byte\r\n                one_byte_reverse = \\\r\n                    eight_bit_reverse_int.to_bytes(1, 'little')  # 1 is for one byte as length, e.g 15 => 0x0f\r\n\r\n                # Substitute one_byte with one_byte_reverse in the  input binary_stream\r\n                binary_stream = binary_stream[0:byte_to_reverse_index]\\\r\n                                + one_byte_reverse \\\r\n                                + binary_stream[byte_to_reverse_index+1:]\r\n        elif iu_config['stream_fuzzing_policy'] == 'other':\r\n            # No other policy implement yet:)\r\n            pass\r\n        return binary_stream\r\n\r\n\r\ndef main(argv):\r\n    host_id = 'host2_min'\r\n    amount_of_testdata = 10000\r\n    iu = IncrementalUpdate(host_id=host_id)\r\n    for i in range(0, amount_of_testdata, 1):\r\n        iu.incremental_update(sequential_number=i)\r\n\r\n    print('%s test data was generate' % amount_of_testdata)\r\n\r\n\r\nif __name__ == '__main__':\r\n    main(sys.argv)\r\n\r\n\r\n\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- incremental_update/pdf_file_incremental_update_6.py	(revision d4d03ddfde2819b63beac2181806c5835b9cc5c3)
+++ incremental_update/pdf_file_incremental_update_6.py	(date 1579088927295)
@@ -365,8 +365,8 @@
         return binary_stream
 
 
-def main(argv):
-    host_id = 'host2_min'
+def main():
+    host_id = 'host1_max'
     amount_of_testdata = 10000
     iu = IncrementalUpdate(host_id=host_id)
     for i in range(0, amount_of_testdata, 1):
@@ -376,7 +376,7 @@
 
 
 if __name__ == '__main__':
-    main(sys.argv)
+    main()
 
 
 
Index: config.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>iu_config = {\r\n    'single_object_update': False,  # [False, True]\r\n    # The below option use only if 'single_object_update' set to False\r\n    'portion_of_rewrite_objects': 1/3.,  # [1/4., 1/3., 1/2.] /**/ {host1_max: 1/5., host2_min: 1/3., host3_avg: 1/4.}\r\n    #\r\n    'update_policy': 'random',  # ['random', 'bottom_up', 'top-down'] /**/ {'bottom_up' for sou and 'random' for mou}\r\n    'getting_object_policy': 'sequential',  # ['sequential', 'random']\r\n\r\n    # Old pdf file path (same hosts)\r\n    'number_of_hosts': 3,\r\n    'raw_host_directory': 'incremental_update/hosts/rawhost_new/',  # raw hosts root directory path, update to new path 13970305\r\n    'host1': 'incremental_update/hosts/rawhost_new/host1_max.pdf',  # host1 relative path\r\n    'host2': 'incremental_update/hosts/rawhost_new/host2_min.pdf',  # host2 relative path\r\n    'host3': 'incremental_update/hosts/rawhost_new/host3_avg.pdf',  # host3 relative path\r\n    'host123': 'incremental_update/hosts/rawhost/host123.pdf',  # host123 full path\r\n\r\n    # New generated/fuzzed objects path (by deep learning model)\r\n    'baseline_object_path': 'incremental_update/hosts/baseline/baseline_obj_1193_from_testset_ii.txt',\r\n    'new_objects_path': 'generated_results/pdfs/_newest_objects/',  # Not set yet\r\n    'stream_directory_path': 'dataset/pdfs/small_size_dataset/binary_streams/',\r\n    'stream_fuzzing_policy': 'basic_random',  # ['basic_random', 'other']\r\n\r\n    # New pdf files by attaching above new pdf objects\r\n    'new_pdfs_directory': 'incremental_update/new_pdfs/',   # new generated pdf file root directory\r\n    'iupdf_host1': 'incremental_update/new_pdfs/host1/',\r\n    'iupdf_host2': 'incremental_update/new_pdfs/host2/',\r\n    'iupdf_host3': 'incremental_update/new_pdfs/host3/',\r\n\r\n    # configuration setting to measure code coverage\r\n    'sut_dir': 'D:/afl/mupdf/platform/win32/Release/',\r\n    'sut_path': 'D:/afl/mupdf/platform/win32/Release/mutool.exe',\r\n    'sut_arguments': ' clean -difa ',\r\n    \r\n    'visual_studio_developer_cmd_path':\r\n        'C:/Program Files (x86)/Microsoft Visual Studio 14.0/Team Tools/Performance Tools/',\r\n}\r\n\r\n\r\nlearning_config = {\r\n    'file_fromat': 'pdf',  # ['pdf', 'xml', 'html', 'png']\r\n    'dataset_size': 'large',  # ['small', 'medium', 'large'] # switch to large dataset date: 1397-02-12\r\n    'small_training_set_path': './dataset/pdfs/small_size_dataset/'\r\n                               '06_object_id__object_len_485080_iqr_cleaned_with_2_column_477104_'\r\n                               'trainset_47711_shuffle_ii.txt',\r\n    'small_validation_set_path': './dataset/pdfs/small_size_dataset/'\r\n                                 '06_object_id__object_len_485080_iqr_cleaned_with_2_column_477104_'\r\n                                 'validationset_11927_shuffle_ii.txt',\r\n    'small_testing_set_path': './dataset/pdfs/small_size_dataset/'\r\n                                 '06_object_id__object_len_485080_iqr_cleaned_with_2_column_477104_'\r\n                                 'testset_35784_shuffle_ii.txt',\r\n\r\n    'medium_training_set_path': './dataset/pdfs/medium_size_dataset/'\r\n                               '07_object_id__object_len_485080_iqr_cleaned_with_2_column_477104_'\r\n                               'trainset_47711_shuffle_ii.txt',\r\n    'medium_validation_set_path': './dataset/pdfs/medium_size_dataset/'\r\n                                 '07_object_id__object_len_485080_iqr_cleaned_with_2_column_477104_'\r\n                                 'validationset_11927_shuffle_ii.txt',\r\n    'medium_testing_set_path': './dataset/pdfs/medium_size_dataset/'\r\n                                 '07_object_id__object_len_485080_iqr_cleaned_with_2_column_477104_'\r\n                                 'testset_35784_shuffle_ii.txt',\r\n\r\n    'large_training_set_path': './dataset/pdfs/large_size_dataset/'\r\n                                '05_object_id__object_len_485080_iqr_cleaned_with_2_column_477104_'\r\n                                'trainset_268371_shuffle_ii.txt',\r\n    'large_validation_set_path': './dataset/pdfs/large_size_dataset/'\r\n                                  '05_object_id__object_len_485080_iqr_cleaned_with_2_column_477104_'\r\n                                  'validationset_89457_shuffle_ii.txt',\r\n    'large_testing_set_path': './dataset/pdfs/large_size_dataset/'\r\n                               '05_object_id__object_len_485080_iqr_cleaned_with_2_column_477104_'\r\n                               'testset_119276_shuffle_ii.txt'\r\n}\r\n\r\n\r\npdf_objects_config = {\r\n\r\n}\r\n\r\n\r\npdf_corpus_config = {\r\n    'corpus_root': 'D:/iust_pdf_corpus/corpus_garbage/',\r\n    'pdf_dir1_path': 'D:/iust_pdf_corpus/corpus_garbage/all_00_10kb/',  # 'Set 1 of IUST corpus' ==> 0-10 kb\r\n    'pdf_dir2_path': 'D:/iust_pdf_corpus/corpus_garbage/drive_deh_10_100kb/',  # 'Set 2 of IUST corpus' ==> 10-100 kb\r\n    'pdf_dir3_path': 'D:/iust_pdf_corpus/corpus_garbage/drive_h_100_900kb/',  # 'Set 3 of IUST corpus' ==> 100-900 kb\r\n    'pdf_dir4_path': 'D:/iust_pdf_corpus/corpus_garbage/mozilla/',  # 'Set 4 of IUST corpus' ==> mozilla corpus\r\n\r\n    'corpus_merged': 'D:/iust_pdf_corpus/corpus_merged/',\r\n    'corpus_merged_streams': 'D:/iust_pdf_corpus/corpus_merged_streams/'\r\n}\r\n\r\n\r\n# print(config['portion_of_rewrite_objects'])\r\n# print(learning_config['dataset_size'][2])
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- config.py	(revision d4d03ddfde2819b63beac2181806c5835b9cc5c3)
+++ config.py	(date 1579088927286)
@@ -1,7 +1,7 @@
 iu_config = {
     'single_object_update': False,  # [False, True]
     # The below option use only if 'single_object_update' set to False
-    'portion_of_rewrite_objects': 1/3.,  # [1/4., 1/3., 1/2.] /**/ {host1_max: 1/5., host2_min: 1/3., host3_avg: 1/4.}
+    'portion_of_rewrite_objects': 1/5.,  # [1/4., 1/3., 1/2.] /**/ {host1_max: 1/5., host2_min: 1/3., host3_avg: 1/4.}
     #
     'update_policy': 'random',  # ['random', 'bottom_up', 'top-down'] /**/ {'bottom_up' for sou and 'random' for mou}
     'getting_object_policy': 'sequential',  # ['sequential', 'random']
